{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "from statistics import mean\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from scipy import special\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import torch.linalg as LA\n",
    "from torch.distributions.laplace import Laplace\n",
    "\n",
    "\n",
    "\n",
    "import utils\n",
    "import models\n",
    "import learning_utils\n",
    "from configurations import args_parser, arguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_name': None, 'eval': False, 'data': 'mnist', 'norm_std': 0.5, 'norm_mean': 0.5, 'train_batch_size': 20, 'test_batch_size': 1000, 'model': 'cnn2', 'num_users': 30, 'num_users_per_round': 5, 'local_epochs': 1, 'local_iterations': 100, 'global_epochs': 200, 'tau_min': 0.05, 'privacy_noise': 'laplace', 'epsilon_bar': 400, 'optimizer': 'sgd', 'lr': 0.01, 'momentum': 0.5, 'lr_scheduler': False, 'device': device(type='cpu'), 'seed': 0, 'zeta_coeff': 1.05, 'alpha': 5, 'beta': 2, 'gamma': 0.1, 'max_seconds': 300, 'method_choosing_users': 'ALSA', 'data_truncation': 1750, 'choosing_users_verbose': False, 'save_best_model': False, 'privacy': True, 'privacy_choosing_users': True, 'epsilon_sum_deascent_coeff': 0.02, 'delta_f': 0.0008, 'snr_verbose': True, 'max_iterations_alsa': 100}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "args = arguments()\n",
    "#boardio is for the the tensorboardx prensation and textio is for written documentation\n",
    "boardio, textio, best_val_acc, path_best_model, last_model_path = utils.initializations(args)\n",
    "textio.cprint(str(args) if args.__class__.__name__ == 'Namespace' else str(vars(args)))\n",
    "\n",
    "#mnist_train_data, mnist_test_loader  = utils.data(args)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNN2Layer                                --\n",
      "├─Conv2d: 1-1                            156\n",
      "├─Conv2d: 1-2                            906\n",
      "├─Linear: 1-3                            4,850\n",
      "├─Linear: 1-4                            510\n",
      "├─Dropout: 1-5                           --\n",
      "├─Dropout: 1-6                           --\n",
      "├─BatchNorm2d: 1-7                       12\n",
      "├─BatchNorm1d: 1-8                       100\n",
      "=================================================================\n",
      "Total params: 6,534\n",
      "Trainable params: 6,534\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "global model's device: cpu\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "train_data, test_loader = utils.data(args)\n",
    "#input in the CNNs is the number of channels and in linear models is the size of the flatten pictures\n",
    "input, output, train_data, val_loader = utils.data_split(train_data, len(test_loader.dataset), args)\n",
    "\n",
    "# model\n",
    "if args.model == 'mlp':\n",
    "    global_model = models.FC2Layer(input, output)\n",
    "elif args.model == 'cnn2':\n",
    "    global_model = models.CNN2Layer(input, output, args.data)\n",
    "elif args.model == 'cnn3':\n",
    "    if args.data == 'cifar10':\n",
    "        global_model = models.CNN3LayerCifar()\n",
    "    else:\n",
    "        global_model = models.CNN3LayerMnist()\n",
    "elif args.model == 'cnn5':\n",
    "    if args.data == 'mnist' or args.data == 'fashion mnist':\n",
    "        raise ValueError('CNN5 is not supported for MNIST type datasets')\n",
    "    global_model = models.CNN5Layer(input, output)\n",
    "elif args.model == 'linear':\n",
    "    global_model = models.Linear(input, output)\n",
    "\n",
    "\n",
    "\n",
    "textio.cprint(str(summary(global_model)).encode('utf-8', errors='ignore').decode('utf-8', errors='ignore'))\n",
    "global_model = global_model.to(args.device)\n",
    "print(f\"global model's device: {next(global_model.parameters()).device}\")\n",
    "\n",
    "train_criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "test_criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "local_models = utils.federated_setup(global_model, train_data, args, i_i_d=True)\n",
    "utils.update_data_equility_partititon(local_models, args)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     local_models[0].update_privacy_violation_and_reward()\n",
    "#     print(f\"iteration {i}, next_privacy_term is {local_models[0].next_privacy_term}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [55:55<00:00, 16.78s/it]   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "choices_table = np.zeros((args.global_epochs, args.num_users))\n",
    "num_of_obs_arr = np.zeros((1,args.num_users))\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "val_losses_list = []\n",
    "l1_norm_avg_deltha_theta_list = []\n",
    "global_epochs_time_list = []\n",
    "\n",
    "\n",
    "time_counter = 0\n",
    "for global_epoch in tqdm(range(1, args.global_epochs+1)):\n",
    "    \"\"\"Part 1: Choosing Users\"\"\"\n",
    "    for usr_idx in range(args.num_users):\n",
    "        local_models[usr_idx].update_g(global_epoch)\n",
    "        local_models[usr_idx].update_ucb(global_epoch)\n",
    "    \n",
    "    if args.choosing_users_verbose:\n",
    "        print(f\"iteration{global_epoch}\")\n",
    "    a=time.time()\n",
    "    rounds_choise = utils.choose_users(local_models, args, global_epoch, method=args.method_choosing_users)\n",
    "\n",
    "    \n",
    "    #choices_table[global_epoch-1, rounds_choise] = 1\n",
    "    num_of_obs_arr[0,rounds_choise] += 1\n",
    "    for usr_idx in rounds_choise:\n",
    "        local_models[usr_idx].update_emp_avg()\n",
    "        local_models[usr_idx].update_privacy_violation_and_reward()\n",
    "        local_models[usr_idx].increase_num_of_obs()\n",
    "        if args.choosing_users_verbose:\n",
    "            print(f\"user {usr_idx}, g: {local_models[usr_idx].g}, ucb: {local_models[usr_idx].ucb}, num_of_obs: {local_models[usr_idx].num_of_obs}, privacy reward: {local_models[usr_idx].privacy_reward}, curr_delay = {local_models[usr_idx].last_access_time}\")\n",
    "    \n",
    "    max_delay = max([local_models[i].last_access_time for i in rounds_choise])\n",
    "    if args.choosing_users_verbose:\n",
    "        print(f\"max_delay = {max_delay:.2f} seconds\")\n",
    "    \n",
    "    \n",
    "    \"\"\"Part 2: Training\"\"\"\n",
    "#     learning_utils.distribute_model(local_models, global_model)\n",
    "#     users_avg_loss_over_local_epochs = []\n",
    "\n",
    "#     for user_idx in rounds_choise:\n",
    "#         user_loss = []\n",
    "#         for local_epoch in range(args.local_epochs):\n",
    "#             user = local_models[user_idx]\n",
    "#             train_loss = learning_utils.train_one_epoch(user, train_criterion, args)\n",
    "#             if args.lr_scheduler:\n",
    "#                 user.scheduler.step(train_loss)\n",
    "#             user_loss.append(train_loss)\n",
    "#         users_avg_loss_over_local_epochs.append(mean(user_loss))\n",
    "    \n",
    "#     avg_loss_over_chosen_users_curr_global_epoch = mean(users_avg_loss_over_local_epochs)\n",
    "#     train_loss_list.append(avg_loss_over_chosen_users_curr_global_epoch)\n",
    "\n",
    "\n",
    "#     avg_deltha_theta = learning_utils.Fed_avg_models(local_models, global_model, rounds_choise,\n",
    "#                                                       args, snr_verbose = args.snr_verbose)\n",
    "#     # l1_norm_avg_deltha_theta = sum(LA.vector_norm(param.flatten(),1) for param in avg_deltha_theta.values())\n",
    "#     # l1_norm_avg_deltha_theta_list.append(l1_norm_avg_deltha_theta)\n",
    "#     # print(f\"l1_norm_avg_deltha_theta is {l1_norm_avg_deltha_theta}\")\n",
    "    \n",
    "\n",
    "#     val_acc, val_loss = learning_utils.test(test_loader, global_model, test_criterion, args)\n",
    "#     val_acc_list.append(val_acc) ; val_losses_list.append(val_loss)\n",
    "    \n",
    "\n",
    "#     # boardio.add_scalars(\"Losses over time in seconds\", {\"train_loss\":avg_loss_over_chosen_users_curr_global_epoch,\n",
    "#     #                                     \"val_loss\": val_loss}, time.time()-start_time)\n",
    "#     # boardio.add_scalar('Val Accuracy', val_acc, time.time()-start_time)\n",
    "\n",
    "\n",
    "#     time_counter += max_delay\n",
    "#     print((f\"global epoch {global_epoch} has been done artifficialy in {max_delay:.2f} secs, the total time by now is {time_counter:.2f} \\n with avg train loss {avg_loss_over_chosen_users_curr_global_epoch:.3f}, val loss {val_loss:.3f}, avg val acc {val_acc:.2f}%\"))\n",
    "#     global_epochs_time_list.append(time_counter)\n",
    "#     gc.collect()\n",
    "\n",
    "\n",
    "#     if val_acc > best_val_acc and args.save_best_model:\n",
    "#         best_val_acc = val_acc\n",
    "#         torch.save({\"model's state dict\":global_model.state_dict(),\n",
    "#                     \"train_loss_list\": train_loss_list,\n",
    "#                     \"val_acc_list\": val_acc_list,\n",
    "#                     \"val_losses_list\": val_losses_list,\n",
    "#                     \"global_epochs_time_list\": global_epochs_time_list,\n",
    "#                     \"num_of_users\": args.num_users,\n",
    "#                     \"num_of_users_per_round\": args.num_users_per_round,\n",
    "#                     \"l1_norm_avg_deltha_theta_list\": l1_norm_avg_deltha_theta_list}\n",
    "#                     , path_best_model)\n",
    "    \n",
    "    \n",
    "#     torch.save({\"model's state dict\":global_model.state_dict(),\n",
    "#                 \"train_loss_list\": train_loss_list,\n",
    "#                 \"val_acc_list\": val_acc_list,\n",
    "#                 \"val_losses_list\": val_losses_list,\n",
    "#                 \"global_epochs_time_list\": global_epochs_time_list,\n",
    "#                 \"num_of_obs_arr\": num_of_obs_arr.reshape(-1),\n",
    "#                 \"global_epoch\": global_epoch,\n",
    "#                 \"num_of_users\": args.num_users,\n",
    "#                 \"num_of_users_per_round\": args.num_users_per_round,\n",
    "#                 \"l1_norm_avg_deltha_theta_list\": l1_norm_avg_deltha_theta_list}\n",
    "#                 , last_model_path)\n",
    "\n",
    "#     if time_counter > args.max_seconds:\n",
    "#         break\n",
    "\n",
    "# users_idxs = tuple([str(x) for x in range(1,args.num_users+1)])\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(users_idxs, num_of_obs_arr.reshape(-1), width = 0.4)\n",
    "# ax.set_title(\"Number of times each user was chosen\")\n",
    "# ax.set_ylabel(\"number of times\")\n",
    "# ax.set_xlabel(\"user index\")\n",
    "# #boardio.add_figure(\"Number of times each user was chosen\", fig, global_epoch)\n",
    "# plt.savefig(last_model_path.parent / \"Number of times each user was chosen.png\")\n",
    "\n",
    "# #choices_table = choices_table.cumsum(axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
