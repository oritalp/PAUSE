{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "from statistics import mean\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from scipy import special\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import utils\n",
    "import models\n",
    "import learning_utils\n",
    "from configurations import args_parser, arguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_name': 'random selection', 'eval': False, 'data': 'mnist', 'norm_std': 0.5, 'norm_mean': 0.5, 'train_batch_size': 20, 'test_batch_size': 1000, 'model': 'cnn2', 'num_users': 30, 'num_users_per_round': 5, 'local_epochs': 1, 'local_iterations': 100, 'global_epochs': 200, 'tau_min': 0.05, 'privacy_noise': 'laplace', 'epsilon': 4, 'optimizer': 'sgd', 'lr': 0.01, 'momentum': 0.5, 'lr_scheduler': True, 'device': 'cpu', 'seed': 0, 'zeta_coeff': 1.5, 'alpha': 1, 'beta': 2, 'gamma': 1, 'max_seconds': 200, 'method_choosing_users': 'random', 'data_truncation': 900, 'choosing_users_verbose': False}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "args = arguments()\n",
    "#boardio is for the the tensorboardx prensation and textio is for written documentation\n",
    "boardio, textio, best_val_acc, path_best_model, last_model_path = utils.initializations(args)\n",
    "textio.cprint(str(args) if args.__class__.__name__ == 'Namespace' else str(vars(args)))\n",
    "\n",
    "#mnist_train_data, mnist_test_loader  = utils.data(args)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNN2Layer                                --\n",
      "├─Conv2d: 1-1                            156\n",
      "├─Conv2d: 1-2                            906\n",
      "├─Linear: 1-3                            4,850\n",
      "├─Linear: 1-4                            510\n",
      "├─Dropout: 1-5                           --\n",
      "├─Dropout: 1-6                           --\n",
      "=================================================================\n",
      "Total params: 6,422\n",
      "Trainable params: 6,422\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "train_data, test_loader = utils.data(args)\n",
    "#input in the CNNs is the number of channels and in linear models is the size of the flatten pictures\n",
    "input, output, train_data, val_loader = utils.data_split(train_data, len(test_loader.dataset), args)\n",
    "\n",
    "# model\n",
    "if args.model == 'mlp':\n",
    "    global_model = models.FC2Layer(input, output)\n",
    "elif args.model == 'cnn2':\n",
    "    global_model = models.CNN2Layer(input, output, args.data)\n",
    "elif args.model == 'cnn3':\n",
    "    if args.data == 'mnist':\n",
    "        raise ValueError('CNN3 is not supported for MNIST')\n",
    "    global_model = models.CNN3Layer()\n",
    "elif args.model == 'cnn5':\n",
    "    if args.data == 'mnist':\n",
    "        raise ValueError('CNN3 is not supported for MNIST')\n",
    "    global_model = models.CNN5Layer(input, output)\n",
    "elif args.model == 'linear':\n",
    "    global_model = models.Linear(input, output)\n",
    "\n",
    "\n",
    "\n",
    "textio.cprint(str(summary(global_model)).encode('utf-8', errors='ignore').decode('utf-8', errors='ignore'))\n",
    "global_model.to(args.device)\n",
    "\n",
    "train_criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "test_criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "local_models = utils.federated_setup(global_model, train_data, args, i_i_d=True)\n",
    "utils.update_data_equility_partititon(local_models, args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:05<16:52,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 1 has been done artifficialy in 0.90 secs, the total time by now is 0.90 \n",
      " with avg train loss 2.297, avg val loss 2.299, avg val acc 10.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:10<16:33,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 2 has been done artifficialy in 0.90 secs, the total time by now is 1.80 \n",
      " with avg train loss 2.297, avg val loss 2.299, avg val acc 11.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:15<16:38,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 3 has been done artifficialy in 0.90 secs, the total time by now is 2.69 \n",
      " with avg train loss 2.298, avg val loss 2.298, avg val acc 11.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:20<16:39,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 4 has been done artifficialy in 0.81 secs, the total time by now is 3.51 \n",
      " with avg train loss 2.301, avg val loss 2.297, avg val acc 11.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:25<16:42,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 5 has been done artifficialy in 0.87 secs, the total time by now is 4.38 \n",
      " with avg train loss 2.298, avg val loss 2.296, avg val acc 12.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:30<16:30,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 6 has been done artifficialy in 0.86 secs, the total time by now is 5.24 \n",
      " with avg train loss 2.289, avg val loss 2.296, avg val acc 12.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:35<15:48,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 7 has been done artifficialy in 0.80 secs, the total time by now is 6.04 \n",
      " with avg train loss 2.305, avg val loss 2.295, avg val acc 12.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:39<15:16,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 8 has been done artifficialy in 0.76 secs, the total time by now is 6.79 \n",
      " with avg train loss 2.285, avg val loss 2.294, avg val acc 12.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:43<14:48,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 9 has been done artifficialy in 0.92 secs, the total time by now is 7.71 \n",
      " with avg train loss 2.303, avg val loss 2.293, avg val acc 13.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:48<14:26,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 10 has been done artifficialy in 0.83 secs, the total time by now is 8.54 \n",
      " with avg train loss 2.304, avg val loss 2.292, avg val acc 14.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:52<14:11,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 11 has been done artifficialy in 0.90 secs, the total time by now is 9.44 \n",
      " with avg train loss 2.284, avg val loss 2.292, avg val acc 15.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:57<14:03,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 12 has been done artifficialy in 0.78 secs, the total time by now is 10.22 \n",
      " with avg train loss 2.280, avg val loss 2.291, avg val acc 15.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [01:01<13:59,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 13 has been done artifficialy in 0.82 secs, the total time by now is 11.05 \n",
      " with avg train loss 2.302, avg val loss 2.290, avg val acc 16.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [01:06<13:54,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 14 has been done artifficialy in 0.83 secs, the total time by now is 11.88 \n",
      " with avg train loss 2.288, avg val loss 2.289, avg val acc 16.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [01:10<13:39,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 15 has been done artifficialy in 0.89 secs, the total time by now is 12.77 \n",
      " with avg train loss 2.266, avg val loss 2.288, avg val acc 16.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [01:14<13:34,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 16 has been done artifficialy in 0.90 secs, the total time by now is 13.66 \n",
      " with avg train loss 2.297, avg val loss 2.287, avg val acc 16.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [01:19<13:24,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 17 has been done artifficialy in 0.80 secs, the total time by now is 14.46 \n",
      " with avg train loss 2.284, avg val loss 2.286, avg val acc 17.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [01:23<13:22,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 18 has been done artifficialy in 0.91 secs, the total time by now is 15.38 \n",
      " with avg train loss 2.261, avg val loss 2.285, avg val acc 17.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [01:27<13:12,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 19 has been done artifficialy in 0.89 secs, the total time by now is 16.27 \n",
      " with avg train loss 2.299, avg val loss 2.285, avg val acc 17.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [01:32<13:10,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 20 has been done artifficialy in 0.84 secs, the total time by now is 17.11 \n",
      " with avg train loss 2.286, avg val loss 2.284, avg val acc 17.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [01:36<13:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 21 has been done artifficialy in 0.90 secs, the total time by now is 18.01 \n",
      " with avg train loss 2.280, avg val loss 2.283, avg val acc 18.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [01:41<13:00,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 22 has been done artifficialy in 0.85 secs, the total time by now is 18.86 \n",
      " with avg train loss 2.287, avg val loss 2.282, avg val acc 17.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [01:45<12:55,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 23 has been done artifficialy in 0.81 secs, the total time by now is 19.67 \n",
      " with avg train loss 2.278, avg val loss 2.281, avg val acc 18.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [01:49<12:53,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 24 has been done artifficialy in 0.90 secs, the total time by now is 20.58 \n",
      " with avg train loss 2.277, avg val loss 2.280, avg val acc 18.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [01:54<12:57,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 25 has been done artifficialy in 0.86 secs, the total time by now is 21.44 \n",
      " with avg train loss 2.275, avg val loss 2.278, avg val acc 17.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [01:58<12:54,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 26 has been done artifficialy in 0.88 secs, the total time by now is 22.32 \n",
      " with avg train loss 2.263, avg val loss 2.277, avg val acc 17.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [02:03<12:46,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 27 has been done artifficialy in 0.79 secs, the total time by now is 23.11 \n",
      " with avg train loss 2.267, avg val loss 2.276, avg val acc 17.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [02:07<12:42,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 28 has been done artifficialy in 0.89 secs, the total time by now is 24.00 \n",
      " with avg train loss 2.279, avg val loss 2.275, avg val acc 18.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [02:12<12:39,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 29 has been done artifficialy in 0.87 secs, the total time by now is 24.87 \n",
      " with avg train loss 2.257, avg val loss 2.274, avg val acc 18.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [02:16<12:34,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 30 has been done artifficialy in 0.88 secs, the total time by now is 25.75 \n",
      " with avg train loss 2.266, avg val loss 2.273, avg val acc 18.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [02:21<12:40,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 31 has been done artifficialy in 0.83 secs, the total time by now is 26.58 \n",
      " with avg train loss 2.291, avg val loss 2.271, avg val acc 19.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [02:25<12:44,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 32 has been done artifficialy in 0.83 secs, the total time by now is 27.41 \n",
      " with avg train loss 2.286, avg val loss 2.269, avg val acc 19.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [02:30<12:34,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 33 has been done artifficialy in 0.91 secs, the total time by now is 28.31 \n",
      " with avg train loss 2.255, avg val loss 2.267, avg val acc 18.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [02:34<12:22,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 34 has been done artifficialy in 0.85 secs, the total time by now is 29.16 \n",
      " with avg train loss 2.271, avg val loss 2.265, avg val acc 16.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [02:39<12:16,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 35 has been done artifficialy in 0.89 secs, the total time by now is 30.06 \n",
      " with avg train loss 2.260, avg val loss 2.264, avg val acc 16.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [02:43<12:05,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 36 has been done artifficialy in 0.84 secs, the total time by now is 30.90 \n",
      " with avg train loss 2.272, avg val loss 2.262, avg val acc 18.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [02:47<12:01,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 37 has been done artifficialy in 0.84 secs, the total time by now is 31.75 \n",
      " with avg train loss 2.262, avg val loss 2.261, avg val acc 20.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [02:52<11:52,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 38 has been done artifficialy in 0.88 secs, the total time by now is 32.62 \n",
      " with avg train loss 2.275, avg val loss 2.259, avg val acc 20.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [02:56<11:46,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 39 has been done artifficialy in 0.86 secs, the total time by now is 33.48 \n",
      " with avg train loss 2.232, avg val loss 2.256, avg val acc 19.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [03:01<11:46,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 40 has been done artifficialy in 0.72 secs, the total time by now is 34.19 \n",
      " with avg train loss 2.264, avg val loss 2.254, avg val acc 21.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [03:05<11:46,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 41 has been done artifficialy in 0.92 secs, the total time by now is 35.12 \n",
      " with avg train loss 2.235, avg val loss 2.252, avg val acc 21.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [03:10<11:41,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 42 has been done artifficialy in 0.87 secs, the total time by now is 35.99 \n",
      " with avg train loss 2.246, avg val loss 2.250, avg val acc 22.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [03:14<11:39,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 43 has been done artifficialy in 0.88 secs, the total time by now is 36.87 \n",
      " with avg train loss 2.238, avg val loss 2.248, avg val acc 22.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [03:18<11:28,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 44 has been done artifficialy in 0.76 secs, the total time by now is 37.63 \n",
      " with avg train loss 2.264, avg val loss 2.245, avg val acc 23.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [03:23<11:22,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 45 has been done artifficialy in 0.81 secs, the total time by now is 38.44 \n",
      " with avg train loss 2.246, avg val loss 2.243, avg val acc 23.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [03:27<11:18,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 46 has been done artifficialy in 0.85 secs, the total time by now is 39.29 \n",
      " with avg train loss 2.255, avg val loss 2.240, avg val acc 23.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [03:32<11:13,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 47 has been done artifficialy in 0.85 secs, the total time by now is 40.14 \n",
      " with avg train loss 2.241, avg val loss 2.238, avg val acc 23.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [03:36<11:04,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 48 has been done artifficialy in 0.87 secs, the total time by now is 41.01 \n",
      " with avg train loss 2.250, avg val loss 2.236, avg val acc 22.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [03:40<11:00,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 49 has been done artifficialy in 0.88 secs, the total time by now is 41.89 \n",
      " with avg train loss 2.234, avg val loss 2.233, avg val acc 23.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [03:45<11:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 50 has been done artifficialy in 0.70 secs, the total time by now is 42.60 \n",
      " with avg train loss 2.221, avg val loss 2.229, avg val acc 24.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [03:49<11:03,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 51 has been done artifficialy in 0.94 secs, the total time by now is 43.53 \n",
      " with avg train loss 2.244, avg val loss 2.226, avg val acc 24.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [03:54<10:54,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 52 has been done artifficialy in 0.82 secs, the total time by now is 44.36 \n",
      " with avg train loss 2.221, avg val loss 2.222, avg val acc 25.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [03:58<10:43,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 53 has been done artifficialy in 0.83 secs, the total time by now is 45.18 \n",
      " with avg train loss 2.240, avg val loss 2.218, avg val acc 26.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [04:02<10:45,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 54 has been done artifficialy in 0.85 secs, the total time by now is 46.04 \n",
      " with avg train loss 2.241, avg val loss 2.215, avg val acc 26.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55/200 [04:07<10:41,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 55 has been done artifficialy in 0.90 secs, the total time by now is 46.93 \n",
      " with avg train loss 2.210, avg val loss 2.210, avg val acc 26.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [04:11<10:36,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 56 has been done artifficialy in 0.85 secs, the total time by now is 47.79 \n",
      " with avg train loss 2.193, avg val loss 2.205, avg val acc 24.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [04:16<10:45,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 57 has been done artifficialy in 0.90 secs, the total time by now is 48.68 \n",
      " with avg train loss 2.186, avg val loss 2.200, avg val acc 24.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/200 [04:20<10:38,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 58 has been done artifficialy in 0.88 secs, the total time by now is 49.56 \n",
      " with avg train loss 2.181, avg val loss 2.195, avg val acc 23.70%\n",
      "global epoch 59 has been done artifficialy in 0.85 secs, the total time by now is 50.41 \n",
      " with avg train loss 2.206, avg val loss 2.190, avg val acc 25.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [04:30<10:52,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 60 has been done artifficialy in 0.84 secs, the total time by now is 51.25 \n",
      " with avg train loss 2.223, avg val loss 2.185, avg val acc 27.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [04:34<10:33,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 61 has been done artifficialy in 0.89 secs, the total time by now is 52.14 \n",
      " with avg train loss 2.186, avg val loss 2.179, avg val acc 28.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [04:39<10:21,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 62 has been done artifficialy in 0.80 secs, the total time by now is 52.94 \n",
      " with avg train loss 2.192, avg val loss 2.174, avg val acc 30.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [04:43<10:10,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 63 has been done artifficialy in 0.18 secs, the total time by now is 53.13 \n",
      " with avg train loss 2.202, avg val loss 2.168, avg val acc 33.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [04:48<10:05,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 64 has been done artifficialy in 0.86 secs, the total time by now is 53.98 \n",
      " with avg train loss 2.158, avg val loss 2.161, avg val acc 32.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [04:52<10:03,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 65 has been done artifficialy in 0.88 secs, the total time by now is 54.86 \n",
      " with avg train loss 2.168, avg val loss 2.154, avg val acc 35.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66/200 [04:57<09:57,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 66 has been done artifficialy in 0.80 secs, the total time by now is 55.66 \n",
      " with avg train loss 2.163, avg val loss 2.148, avg val acc 35.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [05:01<09:53,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 67 has been done artifficialy in 0.75 secs, the total time by now is 56.41 \n",
      " with avg train loss 2.178, avg val loss 2.141, avg val acc 36.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [05:05<09:40,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 68 has been done artifficialy in 0.88 secs, the total time by now is 57.28 \n",
      " with avg train loss 2.143, avg val loss 2.132, avg val acc 37.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [05:10<09:36,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 69 has been done artifficialy in 0.86 secs, the total time by now is 58.15 \n",
      " with avg train loss 2.119, avg val loss 2.123, avg val acc 38.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [05:14<09:32,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 70 has been done artifficialy in 0.87 secs, the total time by now is 59.01 \n",
      " with avg train loss 2.114, avg val loss 2.113, avg val acc 40.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [05:19<09:28,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 71 has been done artifficialy in 0.86 secs, the total time by now is 59.88 \n",
      " with avg train loss 2.136, avg val loss 2.105, avg val acc 41.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72/200 [05:23<09:16,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 72 has been done artifficialy in 0.89 secs, the total time by now is 60.76 \n",
      " with avg train loss 2.126, avg val loss 2.096, avg val acc 44.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [05:27<09:13,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 73 has been done artifficialy in 0.81 secs, the total time by now is 61.57 \n",
      " with avg train loss 2.109, avg val loss 2.087, avg val acc 44.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 74/200 [05:32<09:11,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 74 has been done artifficialy in 0.76 secs, the total time by now is 62.33 \n",
      " with avg train loss 2.134, avg val loss 2.076, avg val acc 46.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [05:36<09:05,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 75 has been done artifficialy in 0.86 secs, the total time by now is 63.19 \n",
      " with avg train loss 2.072, avg val loss 2.063, avg val acc 47.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [05:40<09:04,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 76 has been done artifficialy in 0.91 secs, the total time by now is 64.10 \n",
      " with avg train loss 2.097, avg val loss 2.052, avg val acc 48.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/200 [05:45<08:59,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 77 has been done artifficialy in 0.92 secs, the total time by now is 65.02 \n",
      " with avg train loss 2.023, avg val loss 2.038, avg val acc 49.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 78/200 [05:49<08:52,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 78 has been done artifficialy in 0.91 secs, the total time by now is 65.93 \n",
      " with avg train loss 2.030, avg val loss 2.024, avg val acc 51.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [05:53<08:48,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 79 has been done artifficialy in 0.88 secs, the total time by now is 66.80 \n",
      " with avg train loss 2.042, avg val loss 2.009, avg val acc 52.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [05:58<08:41,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 80 has been done artifficialy in 0.85 secs, the total time by now is 67.65 \n",
      " with avg train loss 2.024, avg val loss 1.993, avg val acc 53.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [06:02<08:42,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 81 has been done artifficialy in 0.81 secs, the total time by now is 68.46 \n",
      " with avg train loss 2.059, avg val loss 1.976, avg val acc 56.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 82/200 [06:07<08:38,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 82 has been done artifficialy in 0.91 secs, the total time by now is 69.37 \n",
      " with avg train loss 1.947, avg val loss 1.957, avg val acc 55.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 83/200 [06:11<08:37,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 83 has been done artifficialy in 0.94 secs, the total time by now is 70.31 \n",
      " with avg train loss 1.986, avg val loss 1.938, avg val acc 56.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 84/200 [06:16<08:31,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 84 has been done artifficialy in 0.90 secs, the total time by now is 71.21 \n",
      " with avg train loss 1.926, avg val loss 1.916, avg val acc 56.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 85/200 [06:20<08:29,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 85 has been done artifficialy in 0.89 secs, the total time by now is 72.10 \n",
      " with avg train loss 1.925, avg val loss 1.896, avg val acc 57.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 86/200 [06:25<08:29,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 86 has been done artifficialy in 0.89 secs, the total time by now is 72.99 \n",
      " with avg train loss 1.916, avg val loss 1.876, avg val acc 54.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 87/200 [06:29<08:25,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 87 has been done artifficialy in 0.88 secs, the total time by now is 73.87 \n",
      " with avg train loss 1.980, avg val loss 1.856, avg val acc 54.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 88/200 [06:33<08:18,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 88 has been done artifficialy in 0.76 secs, the total time by now is 74.63 \n",
      " with avg train loss 1.883, avg val loss 1.827, avg val acc 55.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 89/200 [06:38<08:13,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 89 has been done artifficialy in 0.90 secs, the total time by now is 75.53 \n",
      " with avg train loss 1.888, avg val loss 1.801, avg val acc 56.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [06:42<08:08,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 90 has been done artifficialy in 0.87 secs, the total time by now is 76.40 \n",
      " with avg train loss 1.791, avg val loss 1.772, avg val acc 57.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [06:47<08:01,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 91 has been done artifficialy in 0.18 secs, the total time by now is 76.58 \n",
      " with avg train loss 1.814, avg val loss 1.744, avg val acc 57.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 92/200 [06:51<07:55,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 92 has been done artifficialy in 0.89 secs, the total time by now is 77.48 \n",
      " with avg train loss 1.835, avg val loss 1.721, avg val acc 57.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 93/200 [06:55<07:47,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 93 has been done artifficialy in 0.86 secs, the total time by now is 78.33 \n",
      " with avg train loss 1.730, avg val loss 1.693, avg val acc 58.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 94/200 [07:00<07:45,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 94 has been done artifficialy in 0.91 secs, the total time by now is 79.24 \n",
      " with avg train loss 1.713, avg val loss 1.667, avg val acc 59.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95/200 [07:04<07:41,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 95 has been done artifficialy in 0.86 secs, the total time by now is 80.10 \n",
      " with avg train loss 1.698, avg val loss 1.635, avg val acc 59.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 96/200 [07:09<07:38,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 96 has been done artifficialy in 0.22 secs, the total time by now is 80.32 \n",
      " with avg train loss 1.808, avg val loss 1.603, avg val acc 59.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 97/200 [07:13<07:31,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 97 has been done artifficialy in 0.87 secs, the total time by now is 81.19 \n",
      " with avg train loss 1.634, avg val loss 1.573, avg val acc 59.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 98/200 [07:17<07:29,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 98 has been done artifficialy in 0.89 secs, the total time by now is 82.07 \n",
      " with avg train loss 1.678, avg val loss 1.545, avg val acc 59.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99/200 [07:22<07:24,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 99 has been done artifficialy in 0.91 secs, the total time by now is 82.99 \n",
      " with avg train loss 1.571, avg val loss 1.506, avg val acc 60.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [07:26<07:17,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 100 has been done artifficialy in 0.89 secs, the total time by now is 83.88 \n",
      " with avg train loss 1.715, avg val loss 1.478, avg val acc 62.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [07:30<07:11,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 101 has been done artifficialy in 0.87 secs, the total time by now is 84.75 \n",
      " with avg train loss 1.610, avg val loss 1.450, avg val acc 63.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 102/200 [07:35<07:06,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 102 has been done artifficialy in 0.80 secs, the total time by now is 85.55 \n",
      " with avg train loss 1.629, avg val loss 1.421, avg val acc 64.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 103/200 [07:39<07:02,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 103 has been done artifficialy in 0.84 secs, the total time by now is 86.40 \n",
      " with avg train loss 1.549, avg val loss 1.391, avg val acc 64.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 104/200 [07:43<06:57,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 104 has been done artifficialy in 0.86 secs, the total time by now is 87.26 \n",
      " with avg train loss 1.629, avg val loss 1.366, avg val acc 66.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [07:48<06:52,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 105 has been done artifficialy in 0.18 secs, the total time by now is 87.43 \n",
      " with avg train loss 1.415, avg val loss 1.336, avg val acc 65.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [07:52<06:47,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 106 has been done artifficialy in 0.93 secs, the total time by now is 88.36 \n",
      " with avg train loss 1.402, avg val loss 1.295, avg val acc 67.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [07:56<06:41,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 107 has been done artifficialy in 0.83 secs, the total time by now is 89.19 \n",
      " with avg train loss 1.486, avg val loss 1.266, avg val acc 69.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 108/200 [08:01<06:37,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 108 has been done artifficialy in 0.82 secs, the total time by now is 90.01 \n",
      " with avg train loss 1.398, avg val loss 1.239, avg val acc 68.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109/200 [08:05<06:32,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 109 has been done artifficialy in 0.85 secs, the total time by now is 90.86 \n",
      " with avg train loss 1.382, avg val loss 1.223, avg val acc 68.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [08:09<06:29,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 110 has been done artifficialy in 0.85 secs, the total time by now is 91.71 \n",
      " with avg train loss 1.365, avg val loss 1.185, avg val acc 69.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 111/200 [08:14<06:24,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 111 has been done artifficialy in 0.86 secs, the total time by now is 92.57 \n",
      " with avg train loss 1.416, avg val loss 1.164, avg val acc 71.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 112/200 [08:18<06:21,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 112 has been done artifficialy in 0.81 secs, the total time by now is 93.38 \n",
      " with avg train loss 1.348, avg val loss 1.140, avg val acc 70.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 113/200 [08:22<06:17,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 113 has been done artifficialy in 0.18 secs, the total time by now is 93.56 \n",
      " with avg train loss 1.200, avg val loss 1.106, avg val acc 71.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 114/200 [08:27<06:12,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 114 has been done artifficialy in 0.79 secs, the total time by now is 94.35 \n",
      " with avg train loss 1.272, avg val loss 1.085, avg val acc 72.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 115/200 [08:31<06:07,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 115 has been done artifficialy in 0.90 secs, the total time by now is 95.26 \n",
      " with avg train loss 1.311, avg val loss 1.064, avg val acc 74.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 116/200 [08:35<06:06,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 116 has been done artifficialy in 0.86 secs, the total time by now is 96.11 \n",
      " with avg train loss 1.296, avg val loss 1.044, avg val acc 74.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 117/200 [08:40<06:01,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 117 has been done artifficialy in 0.88 secs, the total time by now is 96.99 \n",
      " with avg train loss 1.233, avg val loss 1.019, avg val acc 74.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 118/200 [08:44<05:57,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 118 has been done artifficialy in 0.89 secs, the total time by now is 97.88 \n",
      " with avg train loss 1.076, avg val loss 1.001, avg val acc 71.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 119/200 [08:49<05:55,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 119 has been done artifficialy in 0.88 secs, the total time by now is 98.76 \n",
      " with avg train loss 1.270, avg val loss 0.982, avg val acc 74.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [08:53<05:56,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 120 has been done artifficialy in 0.87 secs, the total time by now is 99.63 \n",
      " with avg train loss 1.176, avg val loss 0.967, avg val acc 75.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [08:58<05:48,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 121 has been done artifficialy in 0.83 secs, the total time by now is 100.46 \n",
      " with avg train loss 1.142, avg val loss 0.949, avg val acc 77.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 122/200 [09:02<05:39,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 122 has been done artifficialy in 0.90 secs, the total time by now is 101.35 \n",
      " with avg train loss 1.150, avg val loss 0.913, avg val acc 76.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 123/200 [09:06<05:38,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 123 has been done artifficialy in 0.89 secs, the total time by now is 102.25 \n",
      " with avg train loss 1.099, avg val loss 0.900, avg val acc 77.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 124/200 [09:11<05:34,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 124 has been done artifficialy in 0.90 secs, the total time by now is 103.15 \n",
      " with avg train loss 1.132, avg val loss 0.891, avg val acc 78.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 125/200 [09:15<05:28,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 125 has been done artifficialy in 0.85 secs, the total time by now is 104.00 \n",
      " with avg train loss 1.072, avg val loss 0.870, avg val acc 79.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 126/200 [09:19<05:24,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 126 has been done artifficialy in 0.82 secs, the total time by now is 104.82 \n",
      " with avg train loss 1.090, avg val loss 0.866, avg val acc 77.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 127/200 [09:24<05:19,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 127 has been done artifficialy in 0.92 secs, the total time by now is 105.73 \n",
      " with avg train loss 1.226, avg val loss 0.859, avg val acc 77.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 128/200 [09:29<05:29,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 128 has been done artifficialy in 0.89 secs, the total time by now is 106.63 \n",
      " with avg train loss 1.179, avg val loss 0.840, avg val acc 78.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 129/200 [09:34<05:30,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 129 has been done artifficialy in 0.90 secs, the total time by now is 107.53 \n",
      " with avg train loss 1.063, avg val loss 0.818, avg val acc 78.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 130/200 [09:38<05:27,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 130 has been done artifficialy in 0.80 secs, the total time by now is 108.33 \n",
      " with avg train loss 0.979, avg val loss 0.816, avg val acc 76.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 131/200 [09:43<05:28,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 131 has been done artifficialy in 0.79 secs, the total time by now is 109.12 \n",
      " with avg train loss 0.933, avg val loss 0.807, avg val acc 77.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 132/200 [09:49<05:35,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 132 has been done artifficialy in 0.91 secs, the total time by now is 110.04 \n",
      " with avg train loss 0.924, avg val loss 0.803, avg val acc 76.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 133/200 [09:54<05:33,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 133 has been done artifficialy in 0.74 secs, the total time by now is 110.78 \n",
      " with avg train loss 0.915, avg val loss 0.777, avg val acc 78.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 134/200 [09:59<05:37,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 134 has been done artifficialy in 0.79 secs, the total time by now is 111.57 \n",
      " with avg train loss 0.963, avg val loss 0.768, avg val acc 79.97%\n",
      "global epoch 135 has been done artifficialy in 0.19 secs, the total time by now is 111.76 \n",
      " with avg train loss 1.067, avg val loss 0.750, avg val acc 79.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 136/200 [10:16<07:15,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 136 has been done artifficialy in 0.87 secs, the total time by now is 112.63 \n",
      " with avg train loss 0.917, avg val loss 0.761, avg val acc 78.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 137/200 [10:22<06:58,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 137 has been done artifficialy in 0.87 secs, the total time by now is 113.50 \n",
      " with avg train loss 0.897, avg val loss 0.729, avg val acc 80.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 138/200 [10:28<06:35,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 138 has been done artifficialy in 0.91 secs, the total time by now is 114.41 \n",
      " with avg train loss 0.922, avg val loss 0.734, avg val acc 80.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 139/200 [10:34<06:18,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 139 has been done artifficialy in 0.76 secs, the total time by now is 115.17 \n",
      " with avg train loss 0.975, avg val loss 0.720, avg val acc 80.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140/200 [10:40<06:11,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 140 has been done artifficialy in 0.77 secs, the total time by now is 115.94 \n",
      " with avg train loss 1.014, avg val loss 0.720, avg val acc 79.61%\n",
      "global epoch 141 has been done artifficialy in 0.85 secs, the total time by now is 116.79 \n",
      " with avg train loss 1.035, avg val loss 0.722, avg val acc 79.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 142/200 [10:52<05:53,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 142 has been done artifficialy in 0.84 secs, the total time by now is 117.63 \n",
      " with avg train loss 0.834, avg val loss 0.710, avg val acc 79.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 143/200 [10:58<05:35,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 143 has been done artifficialy in 0.78 secs, the total time by now is 118.40 \n",
      " with avg train loss 0.863, avg val loss 0.692, avg val acc 79.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 144/200 [11:03<05:14,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 144 has been done artifficialy in 0.84 secs, the total time by now is 119.24 \n",
      " with avg train loss 0.899, avg val loss 0.684, avg val acc 79.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 145/200 [11:08<05:01,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 145 has been done artifficialy in 0.87 secs, the total time by now is 120.11 \n",
      " with avg train loss 1.095, avg val loss 0.683, avg val acc 81.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 146/200 [11:13<04:49,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 146 has been done artifficialy in 0.92 secs, the total time by now is 121.03 \n",
      " with avg train loss 0.850, avg val loss 0.672, avg val acc 81.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 147/200 [11:18<04:40,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 147 has been done artifficialy in 0.87 secs, the total time by now is 121.91 \n",
      " with avg train loss 0.923, avg val loss 0.657, avg val acc 82.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 148/200 [11:23<04:36,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 148 has been done artifficialy in 0.85 secs, the total time by now is 122.76 \n",
      " with avg train loss 0.784, avg val loss 0.652, avg val acc 82.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 149/200 [11:29<04:38,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 149 has been done artifficialy in 0.90 secs, the total time by now is 123.66 \n",
      " with avg train loss 0.817, avg val loss 0.650, avg val acc 82.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 150/200 [11:35<04:31,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 150 has been done artifficialy in 0.86 secs, the total time by now is 124.52 \n",
      " with avg train loss 0.838, avg val loss 0.630, avg val acc 83.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 151/200 [11:40<04:21,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 151 has been done artifficialy in 0.86 secs, the total time by now is 125.39 \n",
      " with avg train loss 0.791, avg val loss 0.623, avg val acc 83.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 152/200 [11:45<04:11,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 152 has been done artifficialy in 0.74 secs, the total time by now is 126.13 \n",
      " with avg train loss 0.774, avg val loss 0.616, avg val acc 83.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 153/200 [11:50<04:04,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 153 has been done artifficialy in 0.79 secs, the total time by now is 126.92 \n",
      " with avg train loss 0.739, avg val loss 0.614, avg val acc 83.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 154/200 [11:55<03:57,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 154 has been done artifficialy in 0.86 secs, the total time by now is 127.78 \n",
      " with avg train loss 0.801, avg val loss 0.619, avg val acc 82.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [12:00<03:52,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 155 has been done artifficialy in 0.87 secs, the total time by now is 128.65 \n",
      " with avg train loss 0.904, avg val loss 0.619, avg val acc 82.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [12:05<03:44,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 156 has been done artifficialy in 0.86 secs, the total time by now is 129.51 \n",
      " with avg train loss 0.865, avg val loss 0.602, avg val acc 83.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [12:10<03:36,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 157 has been done artifficialy in 0.89 secs, the total time by now is 130.40 \n",
      " with avg train loss 0.683, avg val loss 0.595, avg val acc 83.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 158/200 [12:15<03:32,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 158 has been done artifficialy in 0.91 secs, the total time by now is 131.31 \n",
      " with avg train loss 0.921, avg val loss 0.587, avg val acc 83.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 159/200 [12:20<03:28,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 159 has been done artifficialy in 0.89 secs, the total time by now is 132.20 \n",
      " with avg train loss 0.721, avg val loss 0.579, avg val acc 84.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [12:27<03:49,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 160 has been done artifficialy in 0.89 secs, the total time by now is 133.09 \n",
      " with avg train loss 0.804, avg val loss 0.574, avg val acc 84.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 161/200 [12:32<03:35,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 161 has been done artifficialy in 0.76 secs, the total time by now is 133.84 \n",
      " with avg train loss 0.629, avg val loss 0.569, avg val acc 84.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 162/200 [12:37<03:24,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 162 has been done artifficialy in 0.78 secs, the total time by now is 134.62 \n",
      " with avg train loss 0.894, avg val loss 0.576, avg val acc 83.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 163/200 [12:42<03:12,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 163 has been done artifficialy in 0.87 secs, the total time by now is 135.49 \n",
      " with avg train loss 0.870, avg val loss 0.571, avg val acc 84.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 164/200 [12:47<03:04,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 164 has been done artifficialy in 0.89 secs, the total time by now is 136.38 \n",
      " with avg train loss 0.814, avg val loss 0.574, avg val acc 84.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 165/200 [12:52<02:57,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 165 has been done artifficialy in 0.77 secs, the total time by now is 137.15 \n",
      " with avg train loss 0.884, avg val loss 0.561, avg val acc 85.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 166/200 [12:58<02:57,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 166 has been done artifficialy in 0.88 secs, the total time by now is 138.03 \n",
      " with avg train loss 0.802, avg val loss 0.556, avg val acc 85.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 167/200 [13:03<02:51,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 167 has been done artifficialy in 0.92 secs, the total time by now is 138.95 \n",
      " with avg train loss 0.700, avg val loss 0.543, avg val acc 86.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 168/200 [13:08<02:43,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 168 has been done artifficialy in 0.79 secs, the total time by now is 139.74 \n",
      " with avg train loss 0.759, avg val loss 0.543, avg val acc 85.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 169/200 [13:13<02:35,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 169 has been done artifficialy in 0.88 secs, the total time by now is 140.62 \n",
      " with avg train loss 0.843, avg val loss 0.546, avg val acc 84.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 170/200 [13:17<02:29,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 170 has been done artifficialy in 0.74 secs, the total time by now is 141.36 \n",
      " with avg train loss 0.733, avg val loss 0.539, avg val acc 85.39%\n",
      "global epoch 171 has been done artifficialy in 0.89 secs, the total time by now is 142.25 \n",
      " with avg train loss 0.832, avg val loss 0.540, avg val acc 85.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 171/200 [13:25<02:43,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 172 has been done artifficialy in 0.83 secs, the total time by now is 143.08 \n",
      " with avg train loss 0.660, avg val loss 0.530, avg val acc 85.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 173/200 [13:37<02:37,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 173 has been done artifficialy in 0.74 secs, the total time by now is 143.82 \n",
      " with avg train loss 0.744, avg val loss 0.539, avg val acc 84.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 174/200 [13:42<02:26,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 174 has been done artifficialy in 0.73 secs, the total time by now is 144.56 \n",
      " with avg train loss 0.604, avg val loss 0.522, avg val acc 85.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 175/200 [13:48<02:21,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 175 has been done artifficialy in 0.85 secs, the total time by now is 145.41 \n",
      " with avg train loss 0.750, avg val loss 0.520, avg val acc 84.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 176/200 [13:53<02:13,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 176 has been done artifficialy in 0.90 secs, the total time by now is 146.31 \n",
      " with avg train loss 0.869, avg val loss 0.521, avg val acc 84.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 177/200 [13:59<02:07,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 177 has been done artifficialy in 0.89 secs, the total time by now is 147.21 \n",
      " with avg train loss 0.833, avg val loss 0.527, avg val acc 84.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 178/200 [14:04<02:01,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 178 has been done artifficialy in 0.19 secs, the total time by now is 147.40 \n",
      " with avg train loss 0.668, avg val loss 0.521, avg val acc 84.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 179/200 [14:10<01:56,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 179 has been done artifficialy in 0.73 secs, the total time by now is 148.13 \n",
      " with avg train loss 0.756, avg val loss 0.523, avg val acc 85.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180/200 [14:15<01:51,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 180 has been done artifficialy in 0.84 secs, the total time by now is 148.96 \n",
      " with avg train loss 0.713, avg val loss 0.507, avg val acc 86.34%\n",
      "global epoch 181 has been done artifficialy in 0.88 secs, the total time by now is 149.84 \n",
      " with avg train loss 0.822, avg val loss 0.506, avg val acc 86.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 182/200 [14:26<01:37,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 182 has been done artifficialy in 0.85 secs, the total time by now is 150.69 \n",
      " with avg train loss 0.845, avg val loss 0.513, avg val acc 86.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 183/200 [14:31<01:31,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 183 has been done artifficialy in 0.86 secs, the total time by now is 151.54 \n",
      " with avg train loss 0.765, avg val loss 0.502, avg val acc 86.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 184/200 [14:37<01:26,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 184 has been done artifficialy in 0.91 secs, the total time by now is 152.45 \n",
      " with avg train loss 0.689, avg val loss 0.507, avg val acc 86.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 185/200 [14:42<01:20,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 185 has been done artifficialy in 0.73 secs, the total time by now is 153.18 \n",
      " with avg train loss 0.676, avg val loss 0.503, avg val acc 86.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 186/200 [14:47<01:15,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 186 has been done artifficialy in 0.82 secs, the total time by now is 154.01 \n",
      " with avg train loss 0.806, avg val loss 0.511, avg val acc 86.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 187/200 [14:53<01:11,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 187 has been done artifficialy in 0.90 secs, the total time by now is 154.91 \n",
      " with avg train loss 0.719, avg val loss 0.497, avg val acc 86.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 188/200 [14:58<01:04,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 188 has been done artifficialy in 0.90 secs, the total time by now is 155.81 \n",
      " with avg train loss 0.624, avg val loss 0.496, avg val acc 85.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 189/200 [15:04<00:59,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 189 has been done artifficialy in 0.90 secs, the total time by now is 156.70 \n",
      " with avg train loss 0.702, avg val loss 0.484, avg val acc 86.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190/200 [15:09<00:54,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 190 has been done artifficialy in 0.76 secs, the total time by now is 157.46 \n",
      " with avg train loss 0.712, avg val loss 0.493, avg val acc 85.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 191/200 [15:14<00:48,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 191 has been done artifficialy in 0.85 secs, the total time by now is 158.32 \n",
      " with avg train loss 0.791, avg val loss 0.484, avg val acc 86.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 192/200 [15:20<00:42,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 192 has been done artifficialy in 0.89 secs, the total time by now is 159.21 \n",
      " with avg train loss 0.557, avg val loss 0.480, avg val acc 86.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 193/200 [15:25<00:37,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 193 has been done artifficialy in 0.77 secs, the total time by now is 159.98 \n",
      " with avg train loss 0.680, avg val loss 0.482, avg val acc 86.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 194/200 [15:30<00:31,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 194 has been done artifficialy in 0.80 secs, the total time by now is 160.79 \n",
      " with avg train loss 0.632, avg val loss 0.477, avg val acc 86.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 195/200 [15:36<00:26,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 195 has been done artifficialy in 0.91 secs, the total time by now is 161.69 \n",
      " with avg train loss 0.719, avg val loss 0.463, avg val acc 87.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 196/200 [15:41<00:21,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 196 has been done artifficialy in 0.90 secs, the total time by now is 162.60 \n",
      " with avg train loss 0.633, avg val loss 0.462, avg val acc 87.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 197/200 [15:46<00:16,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 197 has been done artifficialy in 0.82 secs, the total time by now is 163.42 \n",
      " with avg train loss 0.714, avg val loss 0.455, avg val acc 87.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 198/200 [15:52<00:10,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 198 has been done artifficialy in 0.81 secs, the total time by now is 164.23 \n",
      " with avg train loss 0.739, avg val loss 0.462, avg val acc 87.77%\n",
      "global epoch 199 has been done artifficialy in 0.78 secs, the total time by now is 165.01 \n",
      " with avg train loss 0.785, avg val loss 0.468, avg val acc 87.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:03<00:00,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 200 has been done artifficialy in 0.84 secs, the total time by now is 165.85 \n",
      " with avg train loss 0.556, avg val loss 0.456, avg val acc 87.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "choices_table = np.zeros((args.global_epochs, args.num_users))\n",
    "num_of_obs_arr = np.zeros((1,args.num_users))\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "val_losses_list = []\n",
    "global_epochs_time_list = []\n",
    "\n",
    "\n",
    "time_counter = 0\n",
    "for global_epoch in tqdm(range(1, args.global_epochs+1)):\n",
    "    \"\"\"Part 1: Choosing Users\"\"\"\n",
    "    for usr_idx in range(args.num_users):\n",
    "        local_models[usr_idx].update_g(global_epoch)\n",
    "        local_models[usr_idx].update_ucb(global_epoch)\n",
    "    \n",
    "    if args.choosing_users_verbose:\n",
    "        print(f\"iteration{global_epoch}\")\n",
    "    a=time.time()\n",
    "    rounds_choise = utils.choose_users(local_models, args, method=args.method_choosing_users, privacy=False)\n",
    "    #print(f\"choose_users took {time.time()-a}\")\n",
    "    \n",
    "    #choices_table[global_epoch-1, rounds_choise] = 1\n",
    "    num_of_obs_arr[0,rounds_choise] += 1\n",
    "    for usr_idx in rounds_choise:\n",
    "        local_models[usr_idx].update_emp_avg()\n",
    "        local_models[usr_idx].update_privacy_violation_and_reward()\n",
    "        local_models[usr_idx].increase_num_of_obs()\n",
    "        if args.choosing_users_verbose:\n",
    "            print(f\"user {usr_idx}, g: {local_models[usr_idx].g},curr_delay = {local_models[usr_idx].last_access_time}, ucb: {local_models[usr_idx].ucb} num_of_obs: {local_models[usr_idx].num_of_obs}\")\n",
    "    \n",
    "    max_delay = max([local_models[i].last_access_time for i in rounds_choise])\n",
    "    if args.choosing_users_verbose:\n",
    "        print(f\"max_delay = {max_delay}\")\n",
    "    \n",
    "    \n",
    "    \"\"\"Part 2: Training\"\"\"\n",
    "    learning_utils.distribute_model(local_models, global_model)\n",
    "    users_avg_loss_over_local_epochs = []\n",
    "\n",
    "    for user_idx in rounds_choise:\n",
    "        user_loss = []\n",
    "        for local_epoch in range(args.local_epochs):\n",
    "            user = local_models[user_idx]\n",
    "            train_loss = learning_utils.train_one_epoch(user, train_criterion, args)\n",
    "            if args.lr_scheduler:\n",
    "                user.scheduler.step(train_loss)\n",
    "            user_loss.append(train_loss)\n",
    "        users_avg_loss_over_local_epochs.append(mean(user_loss))\n",
    "    \n",
    "    avg_loss_over_chosen_users_curr_global_epoch = mean(users_avg_loss_over_local_epochs)\n",
    "    train_loss_list.append(avg_loss_over_chosen_users_curr_global_epoch)\n",
    "\n",
    "    #we return deltha_theta only for checking can be removed and fix the return value of the function later on to None\n",
    "    deltha_theta = learning_utils.Fed_avg_models(local_models, global_model, rounds_choise)\n",
    "    val_acc, val_loss = learning_utils.test(test_loader, global_model, test_criterion, args)\n",
    "    val_acc_list.append(val_acc) ; val_losses_list.append(val_loss)\n",
    "    \n",
    "\n",
    "    # boardio.add_scalars(\"Losses over time in seconds\", {\"train_loss\":avg_loss_over_chosen_users_curr_global_epoch,\n",
    "    #                                     \"val_loss\": val_loss}, time.time()-start_time)\n",
    "    # boardio.add_scalar('Val Accuracy', val_acc, time.time()-start_time)\n",
    "\n",
    "\n",
    "    time_counter += max_delay\n",
    "    print((f\"global epoch {global_epoch} has been done artifficialy in {max_delay:.2f} secs, the total time by now is {time_counter:.2f} \\n with avg train loss {avg_loss_over_chosen_users_curr_global_epoch:.3f}, avg val loss {val_loss:.3f}, avg val acc {val_acc:.2f}%\"))\n",
    "    global_epochs_time_list.append(time_counter)\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\"model's state dict\":global_model.state_dict(),\n",
    "                    \"train_loss_list\": train_loss_list,\n",
    "                    \"val_acc_list\": val_acc_list,\n",
    "                    \"val_losses_list\": val_losses_list,\n",
    "                    \"global_epochs_time_list\": global_epochs_time_list,\n",
    "                    \"num_of_users\": args.num_users,\n",
    "                    \"num_of_users_per_round\": args.num_users_per_round}\n",
    "                    , path_best_model)\n",
    "    \n",
    "    \n",
    "    torch.save({\"model's state dict\":global_model.state_dict(),\n",
    "                \"train_loss_list\": train_loss_list,\n",
    "                \"val_acc_list\": val_acc_list,\n",
    "                \"val_losses_list\": val_losses_list,\n",
    "                \"global_epochs_time_list\": global_epochs_time_list,\n",
    "                \"num_of_obs_arr\": num_of_obs_arr.reshape(-1),\n",
    "                \"global_epoch\": global_epoch,\n",
    "                \"num_of_users\": args.num_users,\n",
    "                \"num_of_users_per_round\": args.num_users_per_round}\n",
    "                , last_model_path)\n",
    "\n",
    "    if time_counter > args.max_seconds:\n",
    "        break\n",
    "\n",
    "users_idxs = tuple([str(x) for x in range(1,args.num_users+1)])\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(users_idxs, num_of_obs_arr.reshape(-1), width = 0.4)\n",
    "ax.set_title(\"Number of times each user was chosen\")\n",
    "ax.set_ylabel(\"number of times\")\n",
    "ax.set_xlabel(\"user index\")\n",
    "#boardio.add_figure(\"Number of times each user was chosen\", fig, global_epoch)\n",
    "plt.savefig(last_model_path.parent / \"Number of times each user was chosen.png\")\n",
    "\n",
    "#choices_table = choices_table.cumsum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBSFL brute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdev\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mFL_privacy_mab\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcheckpoints\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mgood results - mnist 700 trunc\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mBSFL brute\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mlast_model.pth.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrandom_selection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdev\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mFL_privacy_mab\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcheckpoints\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mgood results - mnist 700 trunc\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mrandom selection\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mlast_model.pth.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\FL_privacy_mab\\utils.py:351\u001b[0m, in \u001b[0;36mplot_graphs\u001b[1;34m(paths_dict)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_graphs\u001b[39m(paths_dict: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03m    Plots graphs for the given paths dictionary.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m paths_dict:\n\u001b[0;32m    352\u001b[0m         paths_dict[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(value)\n\u001b[0;32m    354\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m15\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "utils.plot_graphs({\"BSFL brute\": r\"C:\\dev\\FL_privacy_mab\\checkpoints\\good results - mnist 700 trunc\\BSFL brute\\last_model.pth.tar\",\n",
    "             \"random_selection\": r\"C:\\dev\\FL_privacy_mab\\checkpoints\\good results - mnist 700 trunc\\random selection\\last_model.pth.tar\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
