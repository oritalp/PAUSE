{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "from statistics import mean\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from scipy import special\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import utils\n",
    "import models\n",
    "import learning_utils\n",
    "from configurations import args_parser, arguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_name': 'random selection', 'eval': False, 'data': 'cifar10', 'norm_std': 0.5, 'norm_mean': 0.5, 'train_batch_size': 20, 'test_batch_size': 1000, 'model': 'cnn5', 'num_users': 1, 'num_users_per_round': 1, 'local_epochs': 1, 'local_iterations': 100, 'global_epochs': 200, 'tau_min': 0.05, 'privacy_noise': 'laplace', 'epsilon': 4, 'optimizer': 'sgd', 'lr': 0.01, 'momentum': 0.5, 'lr_scheduler': True, 'device': 'cpu', 'seed': 0, 'zeta_coeff': 1.5, 'alpha': 1, 'beta': 2, 'gamma': 1, 'max_seconds': 200, 'method_choosing_users': 'random', 'data_truncation': None, 'choosing_users_verbose': False}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "args = arguments()\n",
    "#boardio is for the the tensorboardx prensation and textio is for written documentation\n",
    "boardio, textio, best_val_acc, path_best_model, last_model_path = utils.initializations(args)\n",
    "textio.cprint(str(args) if args.__class__.__name__ == 'Namespace' else str(vars(args)))\n",
    "\n",
    "#mnist_train_data, mnist_test_loader  = utils.data(args)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNN5Layer                                --\n",
      "├─Conv2d: 1-1                            896\n",
      "├─Conv2d: 1-2                            9,248\n",
      "├─Conv2d: 1-3                            18,496\n",
      "├─Conv2d: 1-4                            36,928\n",
      "├─Conv2d: 1-5                            131,200\n",
      "├─MaxPool2d: 1-6                         --\n",
      "├─Linear: 1-7                            8,256\n",
      "├─Linear: 1-8                            2,080\n",
      "├─Linear: 1-9                            330\n",
      "├─Dropout: 1-10                          --\n",
      "├─Dropout: 1-11                          --\n",
      "├─Dropout: 1-12                          --\n",
      "├─BatchNorm2d: 1-13                      64\n",
      "├─BatchNorm2d: 1-14                      128\n",
      "├─BatchNorm2d: 1-15                      128\n",
      "=================================================================\n",
      "Total params: 207,754\n",
      "Trainable params: 207,754\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "train_data, test_loader = utils.data(args)\n",
    "#input in the CNNs is the number of channels and in linear models is the size of the flatten pictures\n",
    "input, output, train_data, val_loader = utils.data_split(train_data, len(test_loader.dataset), args)\n",
    "\n",
    "# model\n",
    "if args.model == 'mlp':\n",
    "    global_model = models.FC2Layer(input, output)\n",
    "elif args.model == 'cnn2':\n",
    "    global_model = models.CNN2Layer(input, output, args.data)\n",
    "elif args.model == 'cnn3':\n",
    "    if args.data == 'mnist':\n",
    "        raise ValueError('CNN3 is not supported for MNIST')\n",
    "    global_model = models.CNN3Layer()\n",
    "elif args.model == 'cnn5':\n",
    "    if args.data == 'mnist':\n",
    "        raise ValueError('CNN3 is not supported for MNIST')\n",
    "    global_model = models.CNN5Layer(input, output)\n",
    "elif args.model == 'linear':\n",
    "    global_model = models.Linear(input, output)\n",
    "\n",
    "\n",
    "\n",
    "textio.cprint(str(summary(global_model)).encode('utf-8', errors='ignore').decode('utf-8', errors='ignore'))\n",
    "global_model.to(args.device)\n",
    "\n",
    "train_criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "test_criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "local_models = utils.federated_setup(global_model, train_data, args, i_i_d=True)\n",
    "utils.update_data_equility_partititon(local_models, args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:19<1:03:32, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 1 has been done artifficialy in 0.43 secs, the total time by now is 0.43 \n",
      " with avg train loss 2.289, avg val loss 2.249, avg val acc 18.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:38<1:03:10, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 2 has been done artifficialy in 1.52 secs, the total time by now is 1.95 \n",
      " with avg train loss 2.214, avg val loss 2.095, avg val acc 26.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:56<1:01:57, 18.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 3 has been done artifficialy in 1.02 secs, the total time by now is 2.97 \n",
      " with avg train loss 2.027, avg val loss 1.881, avg val acc 29.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [01:16<1:02:14, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 4 has been done artifficialy in 1.06 secs, the total time by now is 4.03 \n",
      " with avg train loss 1.924, avg val loss 1.788, avg val acc 33.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [01:35<1:01:53, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 5 has been done artifficialy in 1.32 secs, the total time by now is 5.35 \n",
      " with avg train loss 1.837, avg val loss 1.717, avg val acc 35.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [01:55<1:02:52, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 6 has been done artifficialy in 0.88 secs, the total time by now is 6.23 \n",
      " with avg train loss 1.802, avg val loss 1.657, avg val acc 37.19%\n",
      "global epoch 7 has been done artifficialy in 1.25 secs, the total time by now is 7.48 \n",
      " with avg train loss 1.718, avg val loss 1.593, avg val acc 41.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [02:36<1:04:14, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 8 has been done artifficialy in 0.39 secs, the total time by now is 7.87 \n",
      " with avg train loss 1.683, avg val loss 1.527, avg val acc 42.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [02:56<1:03:57, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 9 has been done artifficialy in 0.85 secs, the total time by now is 8.71 \n",
      " with avg train loss 1.607, avg val loss 1.555, avg val acc 40.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [03:15<1:02:19, 19.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 10 has been done artifficialy in 0.64 secs, the total time by now is 9.35 \n",
      " with avg train loss 1.609, avg val loss 1.477, avg val acc 44.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [03:32<59:49, 18.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 11 has been done artifficialy in 0.05 secs, the total time by now is 9.40 \n",
      " with avg train loss 1.568, avg val loss 1.450, avg val acc 45.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [03:50<58:27, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 12 has been done artifficialy in 0.70 secs, the total time by now is 10.10 \n",
      " with avg train loss 1.542, avg val loss 1.373, avg val acc 47.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [04:08<57:20, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 13 has been done artifficialy in 0.05 secs, the total time by now is 10.15 \n",
      " with avg train loss 1.476, avg val loss 1.385, avg val acc 47.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [04:26<56:29, 18.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 14 has been done artifficialy in 0.91 secs, the total time by now is 11.06 \n",
      " with avg train loss 1.487, avg val loss 1.355, avg val acc 50.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [04:43<55:43, 18.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 15 has been done artifficialy in 1.39 secs, the total time by now is 12.45 \n",
      " with avg train loss 1.434, avg val loss 1.361, avg val acc 49.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [05:01<54:58, 17.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 16 has been done artifficialy in 0.77 secs, the total time by now is 13.22 \n",
      " with avg train loss 1.422, avg val loss 1.296, avg val acc 52.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [05:21<56:09, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 17 has been done artifficialy in 0.05 secs, the total time by now is 13.27 \n",
      " with avg train loss 1.383, avg val loss 1.321, avg val acc 51.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [05:41<57:28, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 18 has been done artifficialy in 0.91 secs, the total time by now is 14.18 \n",
      " with avg train loss 1.401, avg val loss 1.266, avg val acc 54.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [06:00<57:37, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 19 has been done artifficialy in 0.21 secs, the total time by now is 14.39 \n",
      " with avg train loss 1.333, avg val loss 1.220, avg val acc 55.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [06:19<57:27, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 20 has been done artifficialy in 0.98 secs, the total time by now is 15.38 \n",
      " with avg train loss 1.374, avg val loss 1.299, avg val acc 53.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [06:39<57:16, 19.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 21 has been done artifficialy in 0.51 secs, the total time by now is 15.89 \n",
      " with avg train loss 1.345, avg val loss 1.239, avg val acc 55.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [06:58<56:38, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 22 has been done artifficialy in 2.04 secs, the total time by now is 17.93 \n",
      " with avg train loss 1.306, avg val loss 1.188, avg val acc 57.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [07:16<56:07, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 23 has been done artifficialy in 0.15 secs, the total time by now is 18.09 \n",
      " with avg train loss 1.275, avg val loss 1.207, avg val acc 55.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [07:35<55:43, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 24 has been done artifficialy in 1.89 secs, the total time by now is 19.97 \n",
      " with avg train loss 1.255, avg val loss 1.133, avg val acc 59.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [07:55<55:29, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 25 has been done artifficialy in 0.84 secs, the total time by now is 20.82 \n",
      " with avg train loss 1.260, avg val loss 1.151, avg val acc 58.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [08:13<55:04, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 26 has been done artifficialy in 0.63 secs, the total time by now is 21.44 \n",
      " with avg train loss 1.235, avg val loss 1.085, avg val acc 60.55%\n",
      "global epoch 27 has been done artifficialy in 1.41 secs, the total time by now is 22.85 \n",
      " with avg train loss 1.239, avg val loss 1.095, avg val acc 60.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [08:52<55:07, 19.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 28 has been done artifficialy in 0.24 secs, the total time by now is 23.09 \n",
      " with avg train loss 1.190, avg val loss 1.071, avg val acc 61.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [09:11<54:40, 19.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 29 has been done artifficialy in 1.16 secs, the total time by now is 24.25 \n",
      " with avg train loss 1.196, avg val loss 1.212, avg val acc 57.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [09:30<54:00, 19.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 30 has been done artifficialy in 1.52 secs, the total time by now is 25.77 \n",
      " with avg train loss 1.227, avg val loss 1.106, avg val acc 59.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [09:49<53:38, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 31 has been done artifficialy in 0.27 secs, the total time by now is 26.04 \n",
      " with avg train loss 1.157, avg val loss 1.102, avg val acc 60.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [10:08<53:13, 19.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 32 has been done artifficialy in 1.35 secs, the total time by now is 27.39 \n",
      " with avg train loss 1.153, avg val loss 1.042, avg val acc 62.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [10:28<53:10, 19.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 33 has been done artifficialy in 0.53 secs, the total time by now is 27.92 \n",
      " with avg train loss 1.126, avg val loss 1.063, avg val acc 61.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [10:47<52:59, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 34 has been done artifficialy in 1.14 secs, the total time by now is 29.06 \n",
      " with avg train loss 1.120, avg val loss 1.070, avg val acc 61.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [11:06<52:31, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 35 has been done artifficialy in 0.89 secs, the total time by now is 29.95 \n",
      " with avg train loss 1.157, avg val loss 1.111, avg val acc 59.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [11:26<52:47, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 36 has been done artifficialy in 0.55 secs, the total time by now is 30.50 \n",
      " with avg train loss 1.054, avg val loss 1.041, avg val acc 63.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [11:45<52:56, 19.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 37 has been done artifficialy in 1.91 secs, the total time by now is 32.40 \n",
      " with avg train loss 1.150, avg val loss 1.002, avg val acc 64.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [12:04<52:07, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 38 has been done artifficialy in 0.99 secs, the total time by now is 33.39 \n",
      " with avg train loss 1.092, avg val loss 0.983, avg val acc 64.90%\n",
      "global epoch 39 has been done artifficialy in 1.07 secs, the total time by now is 34.45 \n",
      " with avg train loss 1.066, avg val loss 0.973, avg val acc 65.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [12:43<51:14, 19.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 40 has been done artifficialy in 0.39 secs, the total time by now is 34.84 \n",
      " with avg train loss 1.035, avg val loss 1.004, avg val acc 64.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [13:02<51:06, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 41 has been done artifficialy in 1.44 secs, the total time by now is 36.28 \n",
      " with avg train loss 1.059, avg val loss 1.044, avg val acc 63.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [13:21<50:40, 19.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 42 has been done artifficialy in 0.46 secs, the total time by now is 36.74 \n",
      " with avg train loss 1.054, avg val loss 0.970, avg val acc 65.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [13:40<50:00, 19.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 43 has been done artifficialy in 0.19 secs, the total time by now is 36.93 \n",
      " with avg train loss 1.030, avg val loss 1.059, avg val acc 62.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [13:59<49:31, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 44 has been done artifficialy in 0.05 secs, the total time by now is 36.98 \n",
      " with avg train loss 1.050, avg val loss 0.950, avg val acc 66.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [14:18<49:13, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 45 has been done artifficialy in 0.19 secs, the total time by now is 37.17 \n",
      " with avg train loss 1.015, avg val loss 1.003, avg val acc 64.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [14:37<48:51, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 46 has been done artifficialy in 1.51 secs, the total time by now is 38.68 \n",
      " with avg train loss 1.063, avg val loss 0.949, avg val acc 66.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [14:56<48:24, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 47 has been done artifficialy in 0.62 secs, the total time by now is 39.29 \n",
      " with avg train loss 0.973, avg val loss 0.944, avg val acc 66.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [15:15<48:08, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 48 has been done artifficialy in 1.87 secs, the total time by now is 41.17 \n",
      " with avg train loss 1.022, avg val loss 0.970, avg val acc 65.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [15:35<48:38, 19.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 49 has been done artifficialy in 1.48 secs, the total time by now is 42.64 \n",
      " with avg train loss 0.981, avg val loss 0.936, avg val acc 66.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [15:54<48:23, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 50 has been done artifficialy in 0.76 secs, the total time by now is 43.40 \n",
      " with avg train loss 1.016, avg val loss 0.960, avg val acc 66.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [16:14<48:02, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 51 has been done artifficialy in 1.33 secs, the total time by now is 44.73 \n",
      " with avg train loss 0.942, avg val loss 0.991, avg val acc 65.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [16:33<47:47, 19.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 52 has been done artifficialy in 0.55 secs, the total time by now is 45.29 \n",
      " with avg train loss 1.013, avg val loss 0.922, avg val acc 68.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [16:53<47:58, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 53 has been done artifficialy in 2.06 secs, the total time by now is 47.35 \n",
      " with avg train loss 0.946, avg val loss 0.920, avg val acc 67.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [17:13<47:27, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 54 has been done artifficialy in 0.31 secs, the total time by now is 47.67 \n",
      " with avg train loss 0.964, avg val loss 0.930, avg val acc 66.75%\n",
      "global epoch 55 has been done artifficialy in 0.25 secs, the total time by now is 47.91 \n",
      " with avg train loss 0.962, avg val loss 0.929, avg val acc 67.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [17:51<46:45, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 56 has been done artifficialy in 0.05 secs, the total time by now is 47.96 \n",
      " with avg train loss 0.955, avg val loss 0.894, avg val acc 68.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [18:11<46:20, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 57 has been done artifficialy in 0.93 secs, the total time by now is 48.90 \n",
      " with avg train loss 1.005, avg val loss 0.936, avg val acc 66.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/200 [18:30<45:52, 19.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 58 has been done artifficialy in 0.85 secs, the total time by now is 49.75 \n",
      " with avg train loss 0.916, avg val loss 0.899, avg val acc 68.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59/200 [18:49<45:20, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 59 has been done artifficialy in 0.87 secs, the total time by now is 50.62 \n",
      " with avg train loss 0.927, avg val loss 0.905, avg val acc 68.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [19:09<45:21, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 60 has been done artifficialy in 0.32 secs, the total time by now is 50.93 \n",
      " with avg train loss 0.986, avg val loss 0.863, avg val acc 69.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [19:28<45:08, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 61 has been done artifficialy in 0.67 secs, the total time by now is 51.60 \n",
      " with avg train loss 0.907, avg val loss 0.895, avg val acc 68.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [19:48<44:40, 19.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 62 has been done artifficialy in 0.66 secs, the total time by now is 52.27 \n",
      " with avg train loss 0.922, avg val loss 0.891, avg val acc 68.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [20:07<44:14, 19.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 63 has been done artifficialy in 0.45 secs, the total time by now is 52.72 \n",
      " with avg train loss 0.937, avg val loss 0.867, avg val acc 69.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [20:26<43:43, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 64 has been done artifficialy in 1.28 secs, the total time by now is 53.99 \n",
      " with avg train loss 0.897, avg val loss 0.884, avg val acc 69.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [20:46<43:45, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 65 has been done artifficialy in 0.67 secs, the total time by now is 54.66 \n",
      " with avg train loss 0.905, avg val loss 0.892, avg val acc 68.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66/200 [21:05<43:12, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 66 has been done artifficialy in 1.20 secs, the total time by now is 55.86 \n",
      " with avg train loss 0.935, avg val loss 0.889, avg val acc 68.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [21:24<42:46, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 67 has been done artifficialy in 1.32 secs, the total time by now is 57.19 \n",
      " with avg train loss 0.920, avg val loss 0.880, avg val acc 69.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [21:43<42:24, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 68 has been done artifficialy in 0.05 secs, the total time by now is 57.24 \n",
      " with avg train loss 0.911, avg val loss 0.855, avg val acc 70.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [22:02<41:46, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 69 has been done artifficialy in 2.18 secs, the total time by now is 59.42 \n",
      " with avg train loss 0.853, avg val loss 0.859, avg val acc 70.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [22:21<41:18, 19.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 70 has been done artifficialy in 0.39 secs, the total time by now is 59.81 \n",
      " with avg train loss 0.922, avg val loss 0.892, avg val acc 68.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [22:40<40:50, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 71 has been done artifficialy in 1.12 secs, the total time by now is 60.93 \n",
      " with avg train loss 0.894, avg val loss 0.849, avg val acc 70.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72/200 [22:59<40:37, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 72 has been done artifficialy in 0.05 secs, the total time by now is 60.98 \n",
      " with avg train loss 0.874, avg val loss 0.901, avg val acc 68.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [23:18<40:09, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 73 has been done artifficialy in 0.68 secs, the total time by now is 61.66 \n",
      " with avg train loss 0.881, avg val loss 0.847, avg val acc 70.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 74/200 [23:37<39:51, 18.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 74 has been done artifficialy in 0.28 secs, the total time by now is 61.94 \n",
      " with avg train loss 0.839, avg val loss 0.832, avg val acc 70.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [23:56<39:53, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 75 has been done artifficialy in 1.68 secs, the total time by now is 63.62 \n",
      " with avg train loss 0.830, avg val loss 0.857, avg val acc 70.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [24:15<39:27, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 76 has been done artifficialy in 0.70 secs, the total time by now is 64.32 \n",
      " with avg train loss 0.873, avg val loss 0.833, avg val acc 71.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/200 [24:34<39:00, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 77 has been done artifficialy in 1.83 secs, the total time by now is 66.15 \n",
      " with avg train loss 0.841, avg val loss 0.856, avg val acc 70.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 78/200 [24:53<38:31, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 78 has been done artifficialy in 1.92 secs, the total time by now is 68.07 \n",
      " with avg train loss 0.883, avg val loss 0.854, avg val acc 70.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [25:12<38:14, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 79 has been done artifficialy in 1.92 secs, the total time by now is 69.99 \n",
      " with avg train loss 0.921, avg val loss 0.837, avg val acc 70.75%\n",
      "global epoch 80 has been done artifficialy in 0.74 secs, the total time by now is 70.72 \n",
      " with avg train loss 0.847, avg val loss 0.868, avg val acc 69.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [25:54<39:23, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 81 has been done artifficialy in 1.60 secs, the total time by now is 72.32 \n",
      " with avg train loss 0.847, avg val loss 0.871, avg val acc 69.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 82/200 [26:13<38:40, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 82 has been done artifficialy in 0.69 secs, the total time by now is 73.01 \n",
      " with avg train loss 0.830, avg val loss 0.835, avg val acc 71.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 83/200 [26:33<38:45, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 83 has been done artifficialy in 0.81 secs, the total time by now is 73.82 \n",
      " with avg train loss 0.816, avg val loss 0.843, avg val acc 70.87%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "choices_table = np.zeros((args.global_epochs, args.num_users))\n",
    "num_of_obs_arr = np.zeros((1,args.num_users))\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "val_losses_list = []\n",
    "global_epochs_time_list = []\n",
    "\n",
    "\n",
    "time_counter = 0\n",
    "for global_epoch in tqdm(range(1, args.global_epochs+1)):\n",
    "    \"\"\"Part 1: Choosing Users\"\"\"\n",
    "    for usr_idx in range(args.num_users):\n",
    "        local_models[usr_idx].update_g(global_epoch)\n",
    "        local_models[usr_idx].update_ucb(global_epoch)\n",
    "    \n",
    "    if args.choosing_users_verbose:\n",
    "        print(f\"iteration{global_epoch}\")\n",
    "    a=time.time()\n",
    "    rounds_choise = utils.choose_users(local_models, args, method=args.method_choosing_users, privacy=False)\n",
    "    #print(f\"choose_users took {time.time()-a}\")\n",
    "    \n",
    "    #choices_table[global_epoch-1, rounds_choise] = 1\n",
    "    num_of_obs_arr[0,rounds_choise] += 1\n",
    "    for usr_idx in rounds_choise:\n",
    "        local_models[usr_idx].update_emp_avg()\n",
    "        local_models[usr_idx].update_privacy_violation_and_reward()\n",
    "        local_models[usr_idx].increase_num_of_obs()\n",
    "        if args.choosing_users_verbose:\n",
    "            print(f\"user {usr_idx}, g: {local_models[usr_idx].g},curr_delay = {local_models[usr_idx].last_access_time}, ucb: {local_models[usr_idx].ucb} num_of_obs: {local_models[usr_idx].num_of_obs}\")\n",
    "    \n",
    "    max_delay = max([local_models[i].last_access_time for i in rounds_choise])\n",
    "    if args.choosing_users_verbose:\n",
    "        print(f\"max_delay = {max_delay}\")\n",
    "    \n",
    "    \n",
    "    \"\"\"Part 2: Training\"\"\"\n",
    "    learning_utils.distribute_model(local_models, global_model)\n",
    "    users_avg_loss_over_local_epochs = []\n",
    "\n",
    "    for user_idx in rounds_choise:\n",
    "        user_loss = []\n",
    "        for local_epoch in range(args.local_epochs):\n",
    "            user = local_models[user_idx]\n",
    "            train_loss = learning_utils.train_one_epoch(user, train_criterion, args)\n",
    "            if args.lr_scheduler:\n",
    "                user.scheduler.step(train_loss)\n",
    "            user_loss.append(train_loss)\n",
    "        users_avg_loss_over_local_epochs.append(mean(user_loss))\n",
    "    \n",
    "    avg_loss_over_chosen_users_curr_global_epoch = mean(users_avg_loss_over_local_epochs)\n",
    "    train_loss_list.append(avg_loss_over_chosen_users_curr_global_epoch)\n",
    "\n",
    "    #we return deltha_theta only for checking can be removed and fix the return value of the function later on to None\n",
    "    deltha_theta = learning_utils.Fed_avg_models(local_models, global_model, rounds_choise)\n",
    "    val_acc, val_loss = learning_utils.test(test_loader, global_model, test_criterion, args)\n",
    "    val_acc_list.append(val_acc) ; val_losses_list.append(val_loss)\n",
    "    \n",
    "\n",
    "    # boardio.add_scalars(\"Losses over time in seconds\", {\"train_loss\":avg_loss_over_chosen_users_curr_global_epoch,\n",
    "    #                                     \"val_loss\": val_loss}, time.time()-start_time)\n",
    "    # boardio.add_scalar('Val Accuracy', val_acc, time.time()-start_time)\n",
    "\n",
    "\n",
    "    time_counter += max_delay\n",
    "    print((f\"global epoch {global_epoch} has been done artifficialy in {max_delay:.2f} secs, the total time by now is {time_counter:.2f} \\n with avg train loss {avg_loss_over_chosen_users_curr_global_epoch:.3f}, avg val loss {val_loss:.3f}, avg val acc {val_acc:.2f}%\"))\n",
    "    global_epochs_time_list.append(time_counter)\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\"model's state dict\":global_model.state_dict(),\n",
    "                    \"train_loss_list\": train_loss_list,\n",
    "                    \"val_acc_list\": val_acc_list,\n",
    "                    \"val_losses_list\": val_losses_list,\n",
    "                    \"global_epochs_time_list\": global_epochs_time_list,\n",
    "                    \"num_of_users\": args.num_users,\n",
    "                    \"num_of_users_per_round\": args.num_users_per_round}\n",
    "                    , path_best_model)\n",
    "    \n",
    "    \n",
    "    torch.save({\"model's state dict\":global_model.state_dict(),\n",
    "                \"train_loss_list\": train_loss_list,\n",
    "                \"val_acc_list\": val_acc_list,\n",
    "                \"val_losses_list\": val_losses_list,\n",
    "                \"global_epochs_time_list\": global_epochs_time_list,\n",
    "                \"num_of_obs_arr\": num_of_obs_arr.reshape(-1),\n",
    "                \"global_epoch\": global_epoch,\n",
    "                \"num_of_users\": args.num_users,\n",
    "                \"num_of_users_per_round\": args.num_users_per_round}\n",
    "                , last_model_path)\n",
    "\n",
    "    if time_counter > args.max_seconds:\n",
    "        break\n",
    "\n",
    "users_idxs = tuple([str(x) for x in range(1,args.num_users+1)])\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(users_idxs, num_of_obs_arr.reshape(-1), width = 0.4)\n",
    "ax.set_title(\"Number of times each user was chosen\")\n",
    "ax.set_ylabel(\"number of times\")\n",
    "ax.set_xlabel(\"user index\")\n",
    "#boardio.add_figure(\"Number of times each user was chosen\", fig, global_epoch)\n",
    "plt.savefig(last_model_path.parent / \"Number of times each user was chosen.png\")\n",
    "\n",
    "#choices_table = choices_table.cumsum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
